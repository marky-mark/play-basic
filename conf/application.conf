# This is the main configuration file for the application.
# ~~~~~

play.application.loader = "AppLoader"

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!

play.crypto.secret = "o>3<6]^R]ueo1xo]MG^O^O?wMM5gBAfcp9vOtkMVFwsKrul9iVtEvxv87KVY_4aB" //should not commit this
play.crypto.secret=${?ApplicationSecret}

parsers.text.maxLength = 100MB
play.http.parser.maxDiskBuffer = 100MB
parsers.anyContent.maxLength = 100MB

play.ws.acceptAnyCertificate = true

pidfile.path = /dev/null

play.server {
  netty {
    transport = "jdk"
    //Native socket transport has higher performance and produces less garbage but are only available on linux
    transport = ${?PlayServerNettyTransport}
  }
}

metrics {
  name = "default"

  environment = "dev"
  environment = ${?RuntimeEnvironment}

  durationUnit = "MILLISECONDS"
  rateUnit = "MILLISECONDS"
  showSamples = false
  jvm = true
  logback = true

  reporting {
    console {
      enabled = false
    }
    csv {
      enabled = false
    }
    jmx {
      enabled = false
    }
    prometheus {
      enabled = true
    }
  }
}

database {
  config.name = "database.postgres"

  postgres {
    profile = "services.slickbacked.ExtendedPostgresDriver$"
    db {
      url="jdbc:postgresql://localhost:5432/play_basic"
      url=${?PostgresUrl}
      user="playbasic"
      user=${?PostgresUser}
      password="playbasic"
      password=${?PostgresPassword}
    }
  }
}

kafka {
  bootstrap.servers = "localhost:9092"
  bootstrap.servers = ${?KafkaBootstrapServers}

  producer.request.size = "102400000"

  internal-infos-events {
    topic = "internal-infos-events_v1"
    topic = ${?KafkaInternalInfoEventsTopic}
  }

  consumer {
    group-id = "internal-infos-events-consumer-group-v1"
    group-id = ${?KAFKA_GROUP_ID}
    grouping-size = "100"
    grouping-size = ${?BATCH_SIZE}
    grouping-duration = "10s"
    grouping-duration = ${?BATCH_TIME}
    concurrency = "1"  # String to allow for below env configurable
    concurrency = ${?KAFKA_CONSUMER_CONCURRENCY}
    auto-offset-reset = "latest" #earliest to start from the beginning
    auto-offset-reset = ${?AUTO_OFFSET_RESET_CONFIG}
  }
}

controllers-context {
  fork-join-executor {
    parallelism-factor = 2.0
    parallelism-min = 4
    parallelism-max = 12
  }
}

service-context {
  fork-join-executor {
    parallelism-factor = 2.0
    parallelism-min = 4
    parallelism-max = 12
  }
}

consumer-context {
  fork-join-executor {
    parallelism-factor = 2.0
    parallelism-min = 4
    parallelism-max = 12
  }
}